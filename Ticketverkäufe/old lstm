
# Daten vorbereiten für LSTM
def prepare_data_lstm(time_series, time_steps=3):
    X, y = [], []
    for i in range(len(time_series) - time_steps):
        X.append(time_series[i:(i + time_steps)])
        y.append(time_series[i + time_steps])
    return np.array(X), np.array(y)

# LSTM Modell erstellen
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(50))
    model.add(Dense(1))  # Nur eine Ausgabe für die nächste Vorhersage
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Ticketverkaufsdaten normalisieren
def normalize_series(timeSeriesSelected):
    scaler = MinMaxScaler(feature_range=(0, 1))
    return scaler.fit_transform(np.array(timeSeriesSelected).reshape(-1, 1)), scaler

# Ticketverkauf Zeitreihe plotten und Vorhersage visualisieren
def plot_predictions(timeSeriesSelected, predicted_data, year):
    plt.figure(figsize=(10, 6))

    real_data = timeSeriesSelected['Sum Tickets sold']
    plt.plot(timeSeriesSelected['Relative show day'], real_data, color='blue', label='Echte Daten')

    plt.plot(timeSeriesSelected['Relative show day'][-len(predicted_data):], predicted_data, color='red',
             label='Vorhersage')

    plt.xlabel('Relative show day')
    plt.ylabel('Sum Tickets sold')
    plt.title(f'Vorhersage der Ticketverkäufe für ART SHOW YEAR {year} mit LSTM')
    plt.legend()
    plt.grid(True)
    return plt

# Hauptfunktion, die LSTM durchführt und Vorhersagen ausgibt
def lstm_ticket_sales_prediction(timeSeriesSelected, time_steps=3, year=None):
    ticket_sales, scaler = normalize_series(timeSeriesSelected['Sum Tickets sold'].values)

    # Daten für LSTM vorbereiten
    X, y = prepare_data_lstm(ticket_sales, time_steps)

    # LSTM-kompatible Daten
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    # LSTM Modell erstellen
    model = build_lstm_model((X.shape[1], 1))

    # Modell trainieren - hier kein Split auf Trainings- und Testdaten
    model.fit(X, y, epochs=50, batch_size=32)

    # Vorhersagen für die gesamte Zeitreihe machen
    predictions = model.predict(X)
    predictions = scaler.inverse_transform(predictions)
    real_sales = scaler.inverse_transform(y.reshape(-1, 1))

    # Plot der Vorhersagen und realen Daten
    plt.figure(figsize=(10, 6))
    plt.plot(timeSeriesSelected['Relative show day'], real_sales, label="Echte Ticketverkäufe", color='blue')
    plt.plot(timeSeriesSelected['Relative show day'][time_steps:], predictions, label="LSTM Vorhersagen", color='red')
    plt.xlabel('Relative show day')
    plt.ylabel('Sum Tickets sold')
    plt.title(f'Ticketverkäufe mit LSTM Vorhersage - Jahr {year}')
    plt.legend()
    plt.grid(True)
    return plt


OLD LSTM 2:

'''

LSTM Model Training

'''

#Prepare Data for LSTM Model

def prepare_data_lstm(time_series, time_steps=3):
    X, y = [], []
    for i in range(len(time_series) - time_steps):
        X.append(time_series[i:(i + time_steps)])
        y.append(time_series[i + time_steps])
    return np.array(X), np.array(y)

def normalize_series(timeSeriesSelected):
    scaler = MinMaxScaler(feature_range=(0, 1))
    return scaler.fit_transform(np.array(timeSeriesSelected).reshape(-1, 1)), scaler


# Build and train the LSTM model

def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(50))
    model.add(Dense(1))  # Only one output for the next prediction
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model



# Predictions for Art SHow 4

def predict_future_sales(model, scaler, time_series, time_steps=3, future_steps=30):
    predictions = []
    current_input = time_series[-time_steps:]
    for _ in range(future_steps):
        current_input = np.reshape(current_input, (1, time_steps, 1))
        next_prediction = model.predict(current_input)
        predictions.append(next_prediction[0, 0])
        current_input = np.append(current_input[:, 1:, :], np.reshape(next_prediction, (1, 1, 1)), axis=1)
    return scaler.inverse_transform(np.array(predictions).reshape(-1, 1))


def LSTMTraining():

    # Load the data
    df = getCsvData()
    # Combine the data from all three art shows
    combined_data = df[df['Event_Year'].isin([1, 2, 3])]

    # Normalize the combined data
    ticket_sales, scaler = normalize_series(combined_data['Sum Tickets sold'].values)

    # Prepare the data for LSTM
    time_steps = 3
    X, y = prepare_data_lstm(ticket_sales, time_steps)

    # Reshape the data for LSTM
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    # Build the LSTM model
    model = build_lstm_model((X.shape[1], 1))

    # Train the model
    model.fit(X, y, epochs=50, batch_size=32)
    # Predict future sales for Art Show 4
    future_steps = 60  # Number of days to predict
    predicted_sales = predict_future_sales(model, scaler, ticket_sales, time_steps, future_steps)

    plt.figure(figsize=(10, 6))
    plt.plot(range(len(combined_data)), combined_data['Sum Tickets sold'], label='Historical Sales')
    plt.plot(range(len(combined_data), len(combined_data) + future_steps), predicted_sales,
             label='Predicted Sales for Art Show 4', color='red')
    plt.xlabel('Relative show day')
    plt.ylabel('Sum Tickets sold')
    plt.title('Predicted Ticket Sales for Art Show 4')
    plt.legend()
    plt.grid(True)
    return plt




    import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense



# Step 1: Load and preprocess the data
def load_and_preprocess_data():
    script_dir = os.path.dirname(__file__)
    csv_path = os.path.join(script_dir, 'Ticketsales.csv')
    df = pd.read_csv(csv_path)
    df['Event_Year'] = df['Event Name'].apply(lambda x: int(x.split()[-1]))
    df = df.sort_values(by=['Event_Year', 'Relative show day'])
    df = df[['Event_Year', 'Relative show day', 'Sum Tickets sold']]
    return df


# Step 2: Prepare the data for LSTM
def prepare_data(df, time_steps=10):
    scaler = MinMaxScaler(feature_range=(0, 1))
    df['Sum Tickets sold'] = scaler.fit_transform(df[['Sum Tickets sold']])

    X, y = [], []
    for i in range(time_steps, len(df)):
        X.append(df['Sum Tickets sold'].values[i - time_steps:i])
        y.append(df['Sum Tickets sold'].values[i])

    X, y = np.array(X), np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    return X, y, scaler


# Step 3: Build the LSTM model
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(units=50))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model


# Step 4: Train the model
def train_model(model, X_train, y_train, epochs=50, batch_size=32):
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)
    return model


# Step 5: Make predictions
def make_predictions(model, X, scaler):
    predictions = model.predict(X)
    predictions = scaler.inverse_transform(predictions)
    return predictions


# Main function to execute the steps
def lstm_predict_year_4():
    df = load_and_preprocess_data()
    X, y, scaler = prepare_data(df)
    model = build_lstm_model((X.shape[1], 1))
    model = train_model(model, X, y)

    # Predict sales for ART SHOW YEAR 4
    df_year_4 = df[df['Event_Year'] == 3].copy()
    df_year_4['Event_Year'] = 4
    X_year_4, _, _ = prepare_data(df_year_4)
    predictions = make_predictions(model, X_year_4, scaler)

    # Plot the predictions
    plt.figure(figsize=(10, 6))
    plt.plot(predictions, label='Predicted Sales for ART SHOW YEAR 4')
    plt.xlabel('Relative show day')
    plt.ylabel('Sum Tickets sold')
    plt.title('Predicted Ticket Sales for ART SHOW YEAR 4')
    plt.legend()

    return plt



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam

def load_and_preprocess(filename):
    data = pd.read_csv(filename)

    # Drop irrelevant column
    data = data.drop('TicketSalesRevenue', axis=1)

    # Create event name dummies first (but keep original column)
    event_dummies = pd.get_dummies(data['Event Name'], prefix='event')
    data = pd.concat([data, event_dummies], axis=1)

    # One-hot encode weekdays
    weekday_dummies = pd.get_dummies(data['SaleWeekDay'], prefix='weekday')
    data = pd.concat([data, weekday_dummies], axis=1)

    # Sort each event's data chronologically
    events = data.groupby('Event Name', sort=False)
    processed_data = []
    for name, group in events:
        processed_data.append(group.sort_values('Relative show day'))
    data_sorted = pd.concat(processed_data)

    # Drop original categorical columns after sorting (keep Event Name for grouping)
    data_sorted = data_sorted.drop(['SaleWeekDay'], axis=1)

    return data_sorted

def create_sequences(data, look_back=10):
    sequences = []
    targets = []

    feature_columns = ['Relative show day', 'Sum Tickets sold'] + \
                      [col for col in data.columns if col.startswith('weekday_')]

    # Ensure numeric data types
    data[feature_columns] = data[feature_columns].apply(pd.to_numeric, errors='coerce')
    data = data.dropna(subset=feature_columns)

    # Create scaler once and reuse
    numerical_features = ['Relative show day', 'Sum Tickets sold']
    if not hasattr(create_sequences, 'scaler'):
        create_sequences.scaler = MinMaxScaler()
        data[numerical_features] = create_sequences.scaler.fit_transform(data[numerical_features])
    else:
        data[numerical_features] = create_sequences.scaler.transform(data[numerical_features])

    event_groups = data.groupby('Event Name', sort=False)
    for name, group in event_groups:
        features = group[feature_columns].values.astype(np.float32)
        event_targets = group['Sum Tickets sold'].shift(-1).values[:-1]

        for i in range(len(event_targets) - look_back):
            sequences.append(features[i:i + look_back])
            targets.append(event_targets[i + look_back])

    return np.array(sequences), np.array(targets), create_sequences.scaler, data['Event Name'].unique()

def build_model(input_shape):
    model = Sequential([
        LSTM(50, activation='relu', input_shape=input_shape),
        Dense(1)
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    return model

def plot_training_history(history):
    plt.figure(figsize=(12, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss Progression')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend()
    plt.grid(True)
    plt.show()

def plot_predictions(y_true, y_pred, sample_size=100):
    plt.figure(figsize=(12, 6))
    plt.plot(y_true[:sample_size], label='Actual Tickets Sold', marker='o')
    plt.plot(y_pred[:sample_size], label='Predicted Tickets Sold', marker='x')
    plt.title('Actual vs Predicted Ticket Sales')
    plt.ylabel('Tickets Sold')
    plt.xlabel('Time Steps')
    plt.legend()
    plt.grid(True)
    plt.show()

def plot_event_predictions(event_name, model, data, scaler, look_back):
    # Filter and prepare event data
    event_mask = (data['Event Name'] == event_name)
    event_data = data[event_mask].sort_values('Relative show day').copy()

    # Apply original scaling
    numerical_features = ['Relative show day', 'Sum Tickets sold']
    event_data[numerical_features] = scaler.transform(event_data[numerical_features])

    # Create sequences
    feature_columns = ['Relative show day', 'Sum Tickets sold'] + \
                      [col for col in data.columns if col.startswith('weekday_')]
    features = event_data[feature_columns].values.astype(np.float32)
    event_targets = event_data['Sum Tickets sold'].shift(-1).values[:-1]

    X_event, y_event = [], []
    for i in range(len(event_targets) - look_back):
        X_event.append(features[i:i + look_back])
        y_event.append(event_targets[i + look_back])
    X_event, y_event = np.array(X_event), np.array(y_event)

    # Predict and inverse scale
    y_pred = model.predict(X_event)
    data_min = scaler.data_min_[1]
    data_max = scaler.data_max_[1]

    y_true_actual = y_event * (data_max - data_min) + data_min
    y_pred_actual = y_pred.flatten() * (data_max - data_min) + data_min

    # Generate timeline
    relative_days = []
    for seq in X_event:
        last_day = scaler.inverse_transform([[seq[-1, 0], 0]])[0][0]
        relative_days.append(last_day + 1)

    full_days = scaler.inverse_transform(event_data[numerical_features])[:, 0]
    full_sales = scaler.inverse_transform(event_data[numerical_features])[:, 1]

    # Plot results
    plt.figure(figsize=(15, 6))
    plt.plot(full_days, full_sales, label='Actual Sales', marker='o')
    plt.plot(relative_days, y_pred_actual, label='Predicted Sales',
             marker='x', linestyle='--', color='orange')
    plt.title(f'Ticket Sales Predictions for {event_name}')
    plt.xlabel('Relative Show Day')
    plt.ylabel('Tickets Sold')
    plt.legend()
    plt.grid(True)
    plt.show()

if __name__ == "__main__":
    # Parameters
    look_back = 10
    test_size = 0.2
    epochs = 100
    batch_size = 32

    # Load and preprocess data
    data = load_and_preprocess('TicketSales.csv')

    # Create sequences with event tracking
    X, y, scaler, event_names = create_sequences(data, look_back)

    # Split data while maintaining event groups
    event_df = pd.DataFrame({'index': range(len(event_names)), 'event': event_names})
    unique_events = event_df['event'].unique()
    train_events, test_events = train_test_split(unique_events, test_size=test_size, random_state=42)
    train_indices = event_df[event_df['event'].isin(train_events)]['index'].values
    test_indices = event_df[event_df['event'].isin(test_events)]['index'].values

    X_train, X_test = X[train_indices], X[test_indices]
    y_train, y_test = y[train_indices], y[test_indices]

    # Build and train model
    model = build_model((look_back, X.shape[2]))
    history = model.fit(X_train, y_train,
                        epochs=epochs,
                        batch_size=batch_size,
                        validation_data=(X_test, y_test),
                        verbose=1)

    plot_training_history(history)
    plot_event_predictions('ART SHOW YEAR 2', model, data, scaler, look_back)
